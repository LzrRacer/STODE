{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# STODE: Reproducible Spatiotemporal Dynamics Notebook\n",
        "\n",
        "This notebook is intended for **reviewers** and **readers of the STODE paper**.\n",
        "Its goal is to make the end‑to‑end workflow as transparent as possible:\n",
        "\n",
        "- How the spatial transcriptomics data are preprocessed.\n",
        "- How the **VAE** and **potential‑guided neural ODE** are trained.\n",
        "- How **backward simulations** and downstream analyses are run.\n",
        "\n",
        "The notebook is deliberately **high‑level and heavily commented** so that the\n",
        "logic of each step is clear even if you do not execute all cells (full\n",
        "training is computationally expensive)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 0. Prerequisites and project layout\n",
        "\n",
        "This notebook assumes you have cloned the STODE project repository, e.g.\n",
        "\n",
        "```bash\n",
        "git clone https://github.com/LzrRacer/STODE.git\n",
        "cd STODE\n",
        "```\n",
        "\n",
        "and that you have created a conda (or equivalent) environment with the\n",
        "required Python packages (PyTorch, Scanpy, POT, GeomLoss, etc.).\n",
        "\n",
        "The code base is organized in three main parts:\n",
        "\n",
        "- `src/` – model, loss, data, and utility modules (VAE, potential, ODE, etc.).\n",
        "- `scripts/` – command‑line entry points for training, simulation, and analysis.\n",
        "- `data/` and `results/` – input AnnData files and experiment outputs.\n",
        "\n",
        "This notebook will *not* redefine the models; instead, it calls the same\n",
        "scripts that are used for the main experiments, but wraps them in a way that\n",
        "explains **what** is happening and **why** each step is needed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "import os, sys\n",
        "\n",
        "# EDIT THIS if you are running the notebook from a different location\n",
        "PROJECT_ROOT = Path.cwd()  # assumed to be the repo root when you open the notebook\n",
        "print('PROJECT_ROOT =', PROJECT_ROOT)\n",
        "\n",
        "SRC_DIR = PROJECT_ROOT / 'src'\n",
        "SCRIPTS_DIR = PROJECT_ROOT / 'scripts'\n",
        "DATA_DIR = PROJECT_ROOT / 'data'\n",
        "RESULTS_DIR = PROJECT_ROOT / 'results'\n",
        "\n",
        "for p in [SRC_DIR, SCRIPTS_DIR, DATA_DIR, RESULTS_DIR]:\n",
        "    print(' -', p)\n",
        "\n",
        "# Ensure src/ is importable\n",
        "if str(SRC_DIR) not in sys.path:\n",
        "    sys.path.insert(0, str(SRC_DIR))\n",
        "print('\\nPython path updated.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Data preprocessing (MOSTA mouse organogenesis example)\n",
        "\n",
        "The raw spatial transcriptomics data are stored as an AnnData object\n",
        "(`.h5ad`). The preprocessing pipeline performs:\n",
        "\n",
        "1. **Quality control**\n",
        "   - Remove spots with too few detected genes.\n",
        "   - Remove genes expressed in very few spots.\n",
        "2. **Normalization + log transform**\n",
        "   - `sc.pp.normalize_total(adata, target_sum=1e4)`\n",
        "   - `sc.pp.log1p(adata)`\n",
        "3. **Highly variable genes (HVGs)**\n",
        "   - Select ~2,000 informative genes across time points.\n",
        "4. **Batch correction across time points**\n",
        "   - Treat each biological time (`obs['timepoint']`) as a batch.\n",
        "   - Apply ComBat (`sc.pp.combat`) to log‑normalized values.\n",
        "   - This yields **continuous, batch‑corrected expression**, which matches\n",
        "     the Gaussian reconstruction loss used in the VAE.\n",
        "5. **Save preprocessed AnnData** for downstream steps.\n",
        "\n",
        "The goal is that reviewers can see that the model never trains directly on\n",
        "raw counts: all training uses a standardized, batch‑corrected matrix."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import scanpy as sc\n",
        "import numpy as np\n",
        "\n",
        "RAW_DATA_PATH = DATA_DIR / 'mosta_data.h5ad'   # adjust if your filename differs\n",
        "PREPROCESSED_DATA_PATH = DATA_DIR / 'preprocessed.h5ad'\n",
        "\n",
        "print('Reading raw data from:', RAW_DATA_PATH)\n",
        "adata = sc.read_h5ad(RAW_DATA_PATH).copy()\n",
        "print('Raw shape (spots × genes):', adata.shape)\n",
        "print('Timepoints:', sorted(adata.obs['timepoint'].astype(str).unique()))\n",
        "\n",
        "# --- 1) Preserve raw counts ---\n",
        "adata.layers['counts'] = adata.X.copy()\n",
        "adata.raw = adata\n",
        "\n",
        "# --- 2) Define batch as timepoint ---\n",
        "adata.obs['batch'] = adata.obs['timepoint'].astype('category')\n",
        "\n",
        "# --- 3) Basic filters ---\n",
        "sc.pp.filter_cells(adata, min_genes=100)\n",
        "sc.pp.filter_genes(adata, min_cells=10)\n",
        "print('After QC:', adata.shape)\n",
        "\n",
        "# --- 4) Normalize and log1p ---\n",
        "sc.pp.normalize_total(adata, target_sum=1e4)\n",
        "sc.pp.log1p(adata)\n",
        "\n",
        "# --- 5) Highly variable genes ---\n",
        "sc.pp.highly_variable_genes(adata, n_top_genes=2000, subset=True)\n",
        "print('After HVG selection:', adata.shape)\n",
        "\n",
        "# --- 6) Batch correction with ComBat ---\n",
        "sc.pp.combat(adata, key='batch')\n",
        "adata.uns['combat_corrected'] = True\n",
        "\n",
        "# --- 7) Save preprocessed AnnData ---\n",
        "adata.write_h5ad(PREPROCESSED_DATA_PATH)\n",
        "print('Saved preprocessed data to:', PREPROCESSED_DATA_PATH)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. VAE pre‑training (latent representation)\n",
        "\n",
        "The first model component is a **Variational Autoencoder (VAE)** that learns a\n",
        "low‑dimensional latent representation `z` of the batch‑corrected expression.\n",
        "\n",
        "**Architecture (as used in the paper):**\n",
        "\n",
        "- Encoder MLP: input dimension = number of HVGs; hidden layers = `[128, 64]`.\n",
        "- Latent dimension: `d = 8`.\n",
        "- Decoder MLP mirrors the encoder.\n",
        "- Reconstruction loss: **Gaussian (MSE)** on the preprocessed, continuous\n",
        "  expression matrix.\n",
        "- KL regularization to a standard normal prior.\n",
        "\n",
        "The VAE is pre‑trained for ~100 epochs to stabilize the latent space before\n",
        "training the dynamical model. This notebook exposes the configuration used in\n",
        "the scripts and shows how to launch pre‑training.\n",
        "\n",
        "> **Note for reviewers:** full training can take hours on a GPU. You do not\n",
        "> need to rerun it to follow the logic; the next cell is mainly for\n",
        "> transparency and reproducibility."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "PRETRAINED_VAE_OUTPUT_DIR = RESULTS_DIR / 'pretrained_vae'\n",
        "PRETRAINED_VAE_OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "PRETRAINED_VAE_MODEL_PATH = PRETRAINED_VAE_OUTPUT_DIR / 'vae_model_pretrained.pt'\n",
        "\n",
        "config_train_vae = {\n",
        "    'data_path': str(PREPROCESSED_DATA_PATH),\n",
        "    'time_key': 'timepoint',\n",
        "    'spatial_key': 'spatial',\n",
        "    'hidden_dims_str': '128,64',\n",
        "    'latent_dim': 8,\n",
        "    'dropout_rate': 0.1,\n",
        "    'epochs': 100,\n",
        "    'learning_rate': 1e-3,\n",
        "    'batch_size': 128,\n",
        "    'recon_loss_type': 'gaussian',\n",
        "    'kl_weight': 0.005,\n",
        "    'output_model_path': str(PRETRAINED_VAE_MODEL_PATH),\n",
        "    'results_dir': str(PRETRAINED_VAE_OUTPUT_DIR),\n",
        "    'seed': 42,\n",
        "    'device': ''  # empty → auto‑select GPU/CPU in the script\n",
        "}\n",
        "\n",
        "with open(PRETRAINED_VAE_OUTPUT_DIR / 'config_train_vae_only.json', 'w') as f:\n",
        "    json.dump(config_train_vae, f, indent=2)\n",
        "\n",
        "print('VAE config written to:', PRETRAINED_VAE_OUTPUT_DIR / 'config_train_vae_only.json')\n",
        "print('\\nIf you want to actually train the VAE from the notebook, uncomment the cell below.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "skip-execution"
        ]
      },
      "outputs": [],
      "source": [
        "# WARNING: This will run full VAE training and can take a long time.\n",
        "# Uncomment the lines below to execute.\n",
        "\n",
        "import subprocess\n",
        "train_vae_script = SCRIPTS_DIR / '00_train_vae.py'\n",
        "cmd = [\n",
        "    'python', str(train_vae_script),\n",
        "]\n",
        "for k, v in config_train_vae.items():\n",
        "    cmd.append(f'--{k}')\n",
        "    cmd.append(str(v))\n",
        "print('Running:', ' '.join(cmd))\n",
        "subprocess.run(cmd, check=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Generative spatiotemporal dynamics (potential + neural ODE)\n",
        "\n",
        "Once the VAE is pre‑trained, the **dynamical system** is trained on pairs of\n",
        "consecutive time points. Conceptually:\n",
        "\n",
        "1. Each spot at time \\(t_k\\) is encoded to a latent vector \\(z_k\\) and has\n",
        "   spatial coordinates \\(s_k\\).\n",
        "2. We form a **joint state** \\(y_k = [s_k, z_k]\\).\n",
        "3. A learnable **potential field** \\(U(s, z, t)\\) defines an energy landscape\n",
        "   over space–latent–time.\n",
        "4. A **Time‑Aware ODE** network learns a velocity field and is regularized so\n",
        "   that the velocity is consistent with the negative gradient of the potential\n",
        "   (a potential‑guided flow).\n",
        "5. Using a simple Euler integrator, we map states from \\(t_k\\) to \\(t_{k-1}\\)\n",
        "   and match the simulated distribution to the observed distribution at\n",
        "   \\(t_{k-1}\\) using a **sliced Wasserstein distance** (distributional loss).\n",
        "\n",
        "Additional regularization terms encourage:\n",
        "\n",
        "- **Time alignment**: a small regressor predicts biological time from latent\n",
        "  codes, encouraging monotonic trajectories in latent space.\n",
        "- **Force consistency**: the ODE’s velocity agrees with the gradient of the\n",
        "  potential.\n",
        "- **Convergence to a progenitor state**: trajectories at the earliest time\n",
        "  cluster around a learned `t0` anchor.\n",
        "\n",
        "Below we record the configuration used for training this system and show how\n",
        "the training script is invoked."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "GENERATIVE_OUTPUT_DIR = RESULTS_DIR / 'generative_system_training_output'\n",
        "GENERATIVE_OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "TRAINED_MODEL_PATH = GENERATIVE_OUTPUT_DIR / 'system_model_final.pt'\n",
        "\n",
        "config_train_dynamics = {\n",
        "    'data_path': str(PREPROCESSED_DATA_PATH),\n",
        "    'time_key': 'timepoint',\n",
        "    'spatial_key': 'spatial',\n",
        "    'pretrained_vae_path': str(PRETRAINED_VAE_MODEL_PATH),\n",
        "    'spatial_dim': 2,\n",
        "    'vae_hidden_dims': '128,64',\n",
        "    'vae_latent_dim': 8,\n",
        "    'vae_recon_loss_type': 'gaussian',\n",
        "    'vae_kl_weight': 0.005,\n",
        "    'vae_dropout_rate': 0.1,\n",
        "    # Potential + ODE\n",
        "    'potential_time_embedding_dim': 4,\n",
        "    'potential_hidden_dims': '32,16',\n",
        "    'ode_time_embedding_dim': 4,\n",
        "    'ode_hidden_dims': '64,32',\n",
        "    'ode_damping_coeff': 0.01,\n",
        "    # Training\n",
        "    'epochs': 50,\n",
        "    'learning_rate': 5e-4,\n",
        "    'batch_size_transition': 32,\n",
        "    'ode_n_integration_steps': 3,\n",
        "    # Loss weights (see paper Methods)\n",
        "    'loss_weight_vae_recon': 1.0,\n",
        "    'loss_weight_vae_kl': 0.1,\n",
        "    'loss_weight_ode_swd': 1.0,\n",
        "    'loss_weight_time_align': 0.1,\n",
        "    'loss_weight_force_consistency': 0.1,\n",
        "    'loss_weight_t0_distance': 10.0,\n",
        "    'loss_weight_t0_velocity_align': 10.0,\n",
        "    'results_dir': str(GENERATIVE_OUTPUT_DIR),\n",
        "    'seed': 42,\n",
        "    'device': ''\n",
        "}\n",
        "\n",
        "with open(GENERATIVE_OUTPUT_DIR / 'config_train_generative_system.json', 'w') as f:\n",
        "    json.dump(config_train_dynamics, f, indent=2)\n",
        "\n",
        "print('Dynamics config written to:', GENERATIVE_OUTPUT_DIR / 'config_train_generative_system.json')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "skip-execution"
        ]
      },
      "outputs": [],
      "source": [
        "# WARNING: Training the full generative system is compute‑intensive.\n",
        "# Uncomment to launch training from the notebook.\n",
        "\n",
        "import subprocess\n",
        "gen_script = SCRIPTS_DIR / '01_train_generative_system.py'\n",
        "cmd = ['python', str(gen_script)]\n",
        "for k, v in config_train_dynamics.items():\n",
        "    cmd.append(f'--{k}')\n",
        "    cmd.append(str(v))\n",
        "print('Running:', ' '.join(cmd))\n",
        "subprocess.run(cmd, check=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Backward simulation from an observed stage\n",
        "\n",
        "After training, the model can **simulate trajectories backward in biological\n",
        "time**. For example, starting from E11.5, we integrate the learned ODE\n",
        "backwards to reconstruct earlier progenitor states.\n",
        "\n",
        "Conceptually:\n",
        "\n",
        "1. Take the observed AnnData at a late time point (e.g., E11.5).\n",
        "2. Encode each spot into \\(z\\), combine with spatial coordinates \\(s\\) to get\n",
        "   \\(y = [s, z]\\).\n",
        "3. Numerically integrate the ODE backward from \\(t_{\\text{obs}}\\) down to \\(t_0\\).\n",
        "4. Save the full trajectory of states \\(y(t)\\) and associated biological times.\n",
        "\n",
        "The next cell shows the configuration used by the simulation script."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "SIM_BWD_DIR = RESULTS_DIR / 'backward_simulation_from_observed'\n",
        "SIM_BWD_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Here we assume the latest timepoint in PREPROCESSED_DATA_PATH is E11.5\n",
        "LATEST_TIME = 11.5\n",
        "SNAPSHOT_PATH = DATA_DIR / f'snapshot_E{LATEST_TIME}.h5ad'  # created in the paper workflow\n",
        "\n",
        "config_sim_bwd = {\n",
        "    'model_load_path': str(TRAINED_MODEL_PATH),\n",
        "    'config_train_load_path': str(GENERATIVE_OUTPUT_DIR / 'config_train_generative_system.json'),\n",
        "    'original_adata_path_for_vae_input_dim': str(PREPROCESSED_DATA_PATH),\n",
        "    'observed_adata_path': str(SNAPSHOT_PATH if SNAPSHOT_PATH.exists() else PREPROCESSED_DATA_PATH),\n",
        "    'observed_time_point_numeric': LATEST_TIME,\n",
        "    't_final_bio_target': 0.0,\n",
        "    'num_cells_to_sample_from_observed': 0,\n",
        "    'output_dir': str(SIM_BWD_DIR),\n",
        "    'simulation_n_steps': 300,\n",
        "    'grid_size': 0,   # set >0 to enable spatial merging / coarse‑graining\n",
        "    'seed': 45,\n",
        "    'device': ''\n",
        "}\n",
        "\n",
        "print('Simulation output directory:', SIM_BWD_DIR)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "skip-execution"
        ]
      },
      "outputs": [],
      "source": [
        "# As before, this call can be long; it is shown for reproducibility.\n",
        "\n",
        "import subprocess\n",
        "sim_script = SCRIPTS_DIR / '02_simulate_backward_from_observed.py'\n",
        "cmd = ['python', str(sim_script)]\n",
        "for k, v in config_sim_bwd.items():\n",
        "    cmd.append(f'--{k}')\n",
        "    cmd.append(str(v))\n",
        "print('Running:', ' '.join(cmd))\n",
        "subprocess.run(cmd, check=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Analysis and visualization helpers\n",
        "\n",
        "Once trajectories have been simulated, several analysis scripts can be run to\n",
        "reproduce figures similar to those in the manuscript:\n",
        "\n",
        "- **Backward contraction / forward replay animations** of the tissue\n",
        "  (morphological changes over time).\n",
        "- **Temporal clustering** and mapping of simulated particles to observed\n",
        "  annotations.\n",
        "- **Latent dynamics summaries** (e.g., how cluster‑wise latent coordinates\n",
        "  evolve over simulated time).\n",
        "- **Potential and divergence maps**, showing regions of expansion and\n",
        "  contraction.\n",
        "\n",
        "For clarity, we only give an example of how to launch the backward animation\n",
        "analysis here; other analyses follow the same pattern (config dictionary →\n",
        "script invocation)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "skip-execution"
        ]
      },
      "outputs": [],
      "source": [
        "ANALYSIS_BWD_DIR = RESULTS_DIR / 'analysis_backward_simulation'\n",
        "ANALYSIS_BWD_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "config_analyze_bwd = {\n",
        "    'backward_simulation_dir': str(SIM_BWD_DIR),\n",
        "    'model_load_path': str(TRAINED_MODEL_PATH),\n",
        "    'config_train_load_path': str(GENERATIVE_OUTPUT_DIR / 'config_train_generative_system.json'),\n",
        "    'original_adata_path_for_vae_config': str(PREPROCESSED_DATA_PATH),\n",
        "    'output_dir': str(ANALYSIS_BWD_DIR),\n",
        "    'animation_frames': 0,          # 0 → use all time points\n",
        "    'animation_fps': 10,\n",
        "    'animation_dot_size': 15,\n",
        "    'latent_compress_method': 'umap',\n",
        "    'latent_compress_umap_neighbors': 15,\n",
        "    'animation_end_time_bio': 0.0,  # stop when reaching t=0\n",
        "    'auto_adjust_fps_to_bio_time': True,\n",
        "    'seed': 46,\n",
        "    'device': ''\n",
        "}\n",
        "\n",
        "# Example (commented) command:\n",
        "import subprocess\n",
        "analyze_script = SCRIPTS_DIR / '03_analyze_backward_simulation.py'\n",
        "cmd = ['python', str(analyze_script)]\n",
        "for k, v in config_analyze_bwd.items():\n",
        "    cmd.append(f'--{k}')\n",
        "    cmd.append(str(v))\n",
        "print('Running:', ' '.join(cmd))\n",
        "subprocess.run(cmd, check=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. How to read this notebook as a reviewer\n",
        "\n",
        "You can use this notebook in two complementary ways:\n",
        "\n",
        "1. **As a narrative of the pipeline**\n",
        "   - Read the markdown cells to understand the modeling choices and how the\n",
        "     command‑line scripts fit together.\n",
        "   - Skim the configuration dictionaries to see exact hyperparameters.\n",
        "2. **As an executable reproduction script (optional)**\n",
        "   - If you have access to the raw data and sufficient compute, you can\n",
        "     progressively uncomment the `subprocess.run(...)` cells to rerun\n",
        "     pre‑training, dynamic training, simulation, and analysis.\n",
        "\n",
        "Either way, the intent is that every major step in STODE’s pipeline is\n",
        "visible in one place, with clear motivation and parameterization."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.x"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
